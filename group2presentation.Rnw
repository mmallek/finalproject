\documentclass[12pt]{beamer}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
%\usepackage{xmpmulti}

\usetheme{Madrid}     % only has title/name/date/slide# at bottom

\usecolortheme{beaver}% beaver is maroon
\definecolor{pastelpink}{rgb}{0.961, .906,.906}
\setbeamertemplate{navigation symbols}{}  % optionally hide navigation buttons 


\title[Group 2 Presentation]{Exploration and Analysis of \\ OpenIntro's ``NCBirths'' Dataset}
\author[Chiang, Mallek, Nu\~nez, Valenzuela]{Jon Chiang, Maritza Mallek, Sara Nu\~nez, Steele Valenzuela}
\institute[]{PUBHLTH 690R: Statistical Modeling and Data Visualization}
\date{24 April 2014}

%\setbeamercolor{author}{fg=white}
%\setbeamercolor{institute}{fg=white}
%\setbeamercolor{date}{fg=white}

\begin{document}

% Load libraries
<<echo=FALSE, message=FALSE>>=
require(ggplot2)
require(GGally)
require(RCurl)
require(knitr)
theme_set(theme_bw())
@
% New libraries for indpendent project
<<echo=FALSE, message=FALSE>>=
require(rpart)
require(tree)
@
% Load data
<<echo=FALSE>>=
births = getURL("https://raw.githubusercontent.com/mmallek/finalproject/master/ncbirths.txt",ssl.verifypeer=FALSE, followlocation=1L, .opts=curlOptions(sslversion=3))
births = read.table(text=births, sep='\t', header=TRUE)
attach(births)
@

\begin{frame}
    \titlepage

    %\vspace{-10ex}
\end{frame} 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Introduction}
\large
\textbf{Overview of Data}
\begin{itemize}
\item Data obtained from OpenIntro
\item Births in North Carolina
\item Random sample of 1000 observations
\item 13 variables
\end{itemize}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Introduction}

\footnotesize

\begin{tabular}{|lp{7cm}l|}
\hline
\textbf{Variable} & \textbf{Definition} & \textbf{Format}\\
\hline
fage & Father’s age in years & integer \\
mage* & Mother’s age in years & integer\\
weeks* & Length of pregnancy in weeks & integer\\
visits & Number of hospital visits during pregnancy & integer\\
gained & Weight gained by mother during pregnancy in pounds & integer \\
weight* & Weight of the baby at birth in pounds & numeric \\
gender & Gender of the baby, female or male & 2-level factor \\
habit & Status of the mother as a nonsmoker or a smoker & 2-level factor  \\
marital & Whether mother is married or not married at birth & 2-level factor \\
whitemom & Whether mother's ethnicity is white or not white & 2-level factor \\
\hline
\end{tabular}

\vspace{1.5em}
* These variables were also coerced into 2-level factors

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Introduction}

\textbf{Response Variable: birth weight of baby}
\begin{itemize}
\item No missing values
\item Could be analyzed as a continuous or categorical response
\item Clear public health application
\end{itemize}
\vspace{1ex}
\textbf{Full Model}
\begin{itemize}
\item Uses all unique variables (no duplicating mature and mage, for example)
\end{itemize}
%\begin{columns}
%\column{.8\textwidth}

\small
<<lm.model, results='hide', tidy.opts=list(keep.blank.line=FALSE, width.cutoff=10)>>=
lm(weight ~ mage + fage + weeks + visits + gained + 
       habit + whitemom + marital + gender, data=births)
@

<<glm.model, results='hide', tidy.opts=list(keep.blank.line=FALSE, width.cutoff=10)>>=
glm(lowbirthweight ~ mage + fage + weeks + visits + gained + habit + whitemom + marital + gender, data=births, family='binomial')
@

%\end{columns}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Sara: Variable Selection and Model Diagnostics}

\textbf{Goals}\\
\begin{itemize}
\item
Write algorithm to run exhaustive model selection \\
\item
Compare models chosen by different selection criterion \\
\item
Check model diagnostics - Was the class of models explored appropriate? \\
\item
Discuss challenges of model selection \\
\end{itemize}

\end{frame}

\begin{frame}{Sara: Variable Selection and Model Diagnostics}

\textbf{Class of models considered in this analysis:} \\
\begin{itemize}
\item
All possible subsets of variables \\
\end{itemize}

\textbf{Criterion used:} \\
\begin{itemize}
\item
Akaike Information Criterion (AIC) \\
\item
Bayes Information Criterion (BIC) \\
\item
Adjusted R squared \\
\end{itemize}

\end{frame}

\begin{frame}[fragile, allowframebreaks]{Sara: Variable Selection and Model Diagnostics}
\textbf{The algorithm} \\
There were 10 possible predictor variables considered in analysis of \emph{NCbirths}. To make it simpler, 4 variables are considered here.\\
\medskip
Creates a matrix where each $row_i$ corresponds to one possible combination of predictor variables \\
% Having trouble displaying output
<<echo=FALSE>>=

# the variable names we want to consider in the model
vars <- c("gained","premie","habit","whitemom")

# create combinations (one column = one possible combination)
one <- combn(vars,1)
two <- combn(vars,2)
three <- combn(vars,3)
four <- combn(vars,4)

ones <- cbind(t(one),0,0,0)
twos <- cbind(t(two),0,0)
threes <- cbind(t(three),0)
fours <- t(four)

combos <- rbind(ones,twos,threes,fours)
threes
@

\end{frame}


\begin{frame}[fragile, allowframebreaks]{Sara: Variable Selection and Model Diagnostics}

Iterate through the rows of the matrix and fit a linear model, with $weight$ as the response variable \\
<<echo=FALSE>>=
mat <- matrix(NA, nrow=15, ncol=3)
colnames(mat) <- c("AIC", "BIC","Adj R^2")
out <- list()
@
\small
<<>>=
for (i in 1:15){
  rowi0 <- combos[i,]
  rowi <- rowi0[rowi0 != 0]
  datai <- as.data.frame(cbind(births[,rowi],births[,"weight"]))
  names(datai) <- c(rowi,"weight")
  mi <- lm(datai$weight~.,data=datai)
  mat[i,] <- c(AIC(mi),BIC(mi),summary(mi)$adj.r.squared)
  out[[i]] <- summary(mi)$coef
  }
@


\end{frame}

\begin{frame}[fragile,allowframebreaks]{Sara: Variable Selection and Model Diagnostics}

<<>>=
# order of linear models based on AIC 
order(mat[,1])
# order of linear models based on BIC 
order(mat[,2])
# order of linear models based on adjusted R^2 
order(mat[,3])
@


\end{frame}

\begin{frame}[fragile,allowframebreaks]{Sara: Variable Selection and Model Diagnostics}
Best model according to AIC and BIC
<<>>=
out[[15]]
@
\end{frame}

\begin{frame}[fragile,allowframebreaks]{Sara: Variable Selection and Model Diagnostics}
Best model according to adjusted $R^2$
<<>>=
out[[14]]
@

Note: Lab exercises explore what to do next...
\end{frame}

\begin{frame}{Sara: Variable Selection and Model Diagnostics}

\textbf{Limitations}
\begin{itemize}
\item
This method does not consider transformations of variables or interactions \\
\item
Model selection is subjective - which criterion is best? - how would you select a model? \\
\item
Differences between possible models are subtle \\
\item
In the actual analysis, wanted to be able to interpret betas, but models were stronger with transformations and interactions - difficult interpretation \\
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Jon: Variable Selection and Model Diagnostics}


\textbf{Regression and Variable Selection}
\begin{itemize}
\item  A regression is a functional relationship between a covariate (predictor) of interest and an outcome of interest. 
\item  One variable can help us predict the value of another variable.
\item The all possible regressions approach looks at all possible combinations or subsets of each and all predictor variables 
\item Fitting the criteria to AIC and BIC to find a good model
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Jon: Variable Selection and Model Diagnostics}

\textbf{Residuals and Leverage}
\begin{itemize}
\item  Determine whether our model assumptions can be used before making an inference
\item  Look for violations and look for the consequential inferential procedures 
\item Combines both graphical and statistical methods. 
\item Leverage = ability to move a regression model by itself by moving in the y direction.  
\item Leverage is always between one and zero 
\item Zero means there is no effect on regression model 

\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Jon: Variable Selection and Model Diagnostics}

\textbf{Cooke's Distance}
\begin{itemize}
\item  Cook's Distance is a measure of the influence an observation has on a fitted line. 
\item The Cook's Distance of the ith observation can be calculated using the following formula:
\item $\frac{r_{i^2}}{p}$ X $\frac{H_{ii}}{1-H_{ii}}$
\item $r_i$ is the value of the {standardised residual} of the ith observation
\item p is the number of parameters and Hii is the ith diagonal term in the Hat Matrix

\end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%     MARITZA     %%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Maritza: Classification and Regression Trees}

\textbf{What are Trees?}
\begin{itemize}
\item Non parametric way to model a dataset. 
\item Binary recursive partitioning used to subdivide dataset
\item Classification trees used when $y$ is a categorical response
\item 2 primary packages in R: tree and rpart
\end{itemize}
\vspace{4ex}
\textbf{Application}
\begin{itemize}
\item Response variable: low birth weight (```low'' or ``not low'')
\item Less than 5.5 lbs considered low (biologically relevant)
\item Initially used tree package, defaults
\end{itemize}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Maritza: Classification and Regression Trees}

\textbf{Initial tree output}
\vspace{-6.5ex}
<< echo=FALSE, fig.height=5.8>>=
form1 = lowbirthweight ~ fage + mage + weeks + visits + marital + gained + gender + habit + whitemom
bt1 = tree(form1, data = births)
plot(bt1)
text(bt1, cex=0.7, pretty=10)
@

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Maritza: Classification and Regression Trees}

%\begin{itemize}

\textbf{Next step: prune using 10-fold cross-validation}
%\end{itemize}
<<tree2, echo=FALSE, fig.height=4>>=
bt1.cv = cv.tree(bt1)
bt1.p = prune.tree(bt1, best=3)
plot(bt1.p)
text(bt1.p, cex=1)
@

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Maritza: Classification and Regression Trees}

\textbf{Prediction?}

\begin{itemize}
\item Seems obvious that weeks would predict low birth weight
\item What about variables not directly associated with pregnancy?
\item Is it fair to include predictors that are measured at the same time as the response?
\item Revised model:
\end{itemize}

\footnotesize
<<model2, results='hide'>>=
lowbirthweight ~ fage + mage + marital + gender + habit + whitemom
@

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Maritza: Classification and Regression Trees}
\textbf{Results}

\begin{itemize}
\item Split once, on marital
\item Neither node contained a majority of ``low birth weight''
\end{itemize}

\vspace{-6ex}
<<echo=FALSE, include=TRUE, fig.height=3, fig.width=4>>=
form2 = lowbirthweight ~ fage + mage  + marital + gender + habit + whitemom
bt2 = tree(form2, data=births)
plot(bt2)
text(bt2, cex=1, all=TRUE, pretty=8)
@
\vspace{-10ex}
\begin{itemize}
\item Next step is to adjust stopping criteria
\end{itemize}

\end{frame} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Maritza: Classification and Regression Trees}

\small
\begin{columns}
\column{0.35\textwidth}
\textbf{Results}
\begin{itemize}
    \item Reran analysis, including pruning, cross-validation
    \item Tree uses 5/6 variables 
    \item High overall deviance (which we want to minimize)
    \item No terminal nodes predicting low birth weight!
\end{itemize}

\column{0.65\textwidth}
<<echo=FALSE, include=TRUE, fig.height=6, fig.width=6>>=
bt2.adj = tree(form2, data=births, control=tree.control(1000, mincut=5, minsize=10, mindev=0.005))
bt2.adj.cv = cv.tree(bt2.adj)
bt2.adj.p = prune.tree(bt2.adj, best=which.min(bt2.adj.cv$dev))
plot(bt2.adj.p)
text(bt2.adj.p, cex=0.6, all=TRUE, pretty=10)
@
\end{columns}
\end{frame} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Maritza: Classification and Regression Trees}
\textbf{Conclusions}
\begin{itemize}
\item We have a negative result for this dataset
    \begin{itemize}
    \item Marital status, smoking, age, and ethnicity not very important 
    \item Or, at least not detectable by the tree
    \end{itemize}
\item Use trees with caution! 
\item Results indicate other (uncollected) data may contain important predictors.
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Steele: Imputation}

- Define method \\
- Name r packages used \\
- Describe process \\
- Success and failure? \\
- Conclusions/Lessons Learned \\


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Conclusion}

\textbf{What did we learn?}
\begin{itemize}
\item Most important variable: weeks
\item Subjective process \\
\item Prediction is difficult \\
\item One R package or function won't do the work for you \\
\end{itemize}
\vspace{2ex}
\textbf{Questions?}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}