\documentclass[11pt]{article}
%\usepackage{geometry}                
%\geometry{letterpaper, top=1.5cm, left=2cm} 
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
\usepackage{url}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{ textcomp }
\usepackage{lscape}
\usepackage{multirow}



\renewcommand{\familydefault}{cmss}

\title{Group 2 Final Project}
\author{PUBHLTH 690R: Statistical Modeling and Data Visualization\\
        Members: Jon Chiang, Maritza Mallek, Sara Nu\~nez, Steele Valenzuela}


\begin{document}
\maketitle

\tableofcontents

\newpage
% Load libraries
<<echo=FALSE, message=FALSE>>=
require(ggplot2)
require(GGally)
require(RCurl)
require(knitr)
theme_set(theme_bw())
#required for Jonathan
require(leaps)
require(xtable)
# required for Maritza
require(rpart)
require(tree)
require(rattle)
require(rpart.plot)
require(Hmisc)
require(Amelia)
require(Zelig)
@
% Load data
<<echo=FALSE>>=
births = getURL("https://raw.githubusercontent.com/mmallek/finalproject/master/ncbirths.txt",ssl.verifypeer=FALSE, followlocation=1L, .opts=curlOptions(sslversion=3))
births = read.table(text=births, sep='\t', header=TRUE)
ncbirths = births
attach(births)
@


% The following is a multiplot function to condense the qplots
<<echo=FALSE>>=
# multiplot function
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  require(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
@

\section{Introduction}
This dataset was acquired from OpenIntro.org's free collection. According to the metadata, `ncbirths' was released in 2004 by North Carolina. This data set has been of interest to medical researchers who are studying the relation between habits and practices of expectant mothers and the birth of their children. The data provided by OpenIntro is a random sample of 1,000 cases from this data set.

Of the 13 variables presented in the dataset, there are several options for thinking about predictors vs. response variables. Some of these are clearly predictors: \verb|fage|, \verb|mage|, \verb|marital|, \verb|habit|, \verb|gender|, \verb|whitemom|. Others could be considered either predictors or responses: \verb|weeks|, \verb|premie|, \verb|visits|, \verb|gained|, \verb|weight| (or \verb|lowbirthweight|). Based on the dataset description, which states that the research was exploring "habits and practices of expectant mothers," our inference is that habits and practices refer to weight gained by the mother and the smoking status of the mother (possibly marital status as well). The most likely responses are (hospital) \verb|visits|, (gestational) \verb|weeks| (related to \verb|premie|), and (baby's birth) \verb|weight| (related to \verb|lowbirthweight|). An additional key characteristic of this dataset is that 6 of the variables are pairs of continuous and categorical data (see Table \ref{table:factors}).

One of the main challenges from this dataset is that we do not have data synced to a gestational age other than at term. The values for \verb|visits|, \verb|weeks|, \verb|weight|, and \verb|gained| are all collected at birth. While it makes sense to include all variables in any exploratory analysis of relationships among these variables, the value of any of these as prediction terms is problematic because they are collected at the end of the pregancy.

We are most interested in the baby's weight at birth, which we will examine in both its continuous and factored format. This is our initial, full model:
<<eval=FALSE>>=
lm(weight ~ mage + fage + weeks + visits + gained + habit + whitemom + marital + gender)
glm(lowbirthweight ~ mage + fage + weeks + visits + gained + habit + whitemom + marital + gender, family=binomial)
@

\begin{landscape}

\begin{table}
\centering
\begin{tabular}{lllll}
\hline
Continuous Variable & Two-level Factor & Equation with factor labels & Observations & NAs\\
\hline
mage & mature & younger mom $< 35 \text{ years}<=$ mature mom & 867/133 & 0\\
weeks & premie & premie $< 37 \text{ weeks}<= $ full term & 846/152 & 2\\
weight & lowbirthweight & low $<= 5.5 \text{ pounds}<$ not low & 111/889 & 0\\
n/a & marital & married OR not married & 386/613 & 1\\
n/a & whitemom & white OR not white & 714/284 & 2 \\
n/a & habit & nonsmoker OR smoker & 873/126 & 1 \\
n/a & gender & female OR male & 503/497 & 0 \\
\end{tabular}
\caption{Factored variables.
\label{table:factors}}
\end{table}



\vspace{3cm}
% To build this table I just went through Steele's paragraphs in "Summary of variables" and converted it to numbers. -M

% to size and wrap a column in a table: p{4cm}
\begin{table}
\centering
\begin{tabular}{ccccccccc}
\hline
Variable & \multirow{2}{*}{\parbox{2cm}{Variable Definitions}}  & Min & Median & Mean & Max & \multirow{2}{*}{\parbox{2cm}{Missing Values}} & 95\% CI for Mean & 95\% CI for Variance\\
 & & & & & & & & \\
\hline
fage & father's age & 14 & 30 & 30.26 & 55 & 171 & (29.7953, 30.71616) & (41.6428, 50.49614)\\
mage & mother's age & 13 & 27 & 27 & 50 & 0 & (26.61489, 27.38511) & (35.4345, 42.23142) \\
weeks & gestational age & 20 & 39 & 38.33 & 45 & 2 & (38.15279, 38.51655) & (7.886806,9.40128) \\
visits & hospital visits & 0 & 12.0 & 12.1 & 30 & 9 & (11.85871,12.35118) & (14.35011,17.11633)\\
%gained & \multirow{2}{*}{weight gained} & 0 & 30 & 30.33 & 85 & 27 \\
%&  by mother & & & & & \\
gained & \multirow{2}{*}{\parbox{3cm}{weight gained by mother}} & 0 & 30 & 30.33 & 85 & 27 & (29.43097,31.22063) & (185.9254,222.1265) \\
 & & & & & & & & \\
weight & birth weight of baby & 1 & 7.31 & 7.101 & 11.750 & 0 & (7.007482,7.194518) & (2.08949,2.490288)\\
\end{tabular}
% This caption is dumb but I am not sure what to put here.
\caption{Continuous variables}
\label{table:continuous}
\end{table}

\end{landscape}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%% Sara's Analysis %%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Model Selection Analysis: Sara Nu\~nez}
\subsection{Methods}
\paragraph{}
This analysis of the $\emph{NCbirths}$ data is concerned with the process of model selection and the differences between several selection criterion. In order to evaluate possible models, code was developed that implements model selection based on all possible subsets of 10 of the 12 possible predictor variables in the dataset. Father's age was not considered in this analysis, as it had a large number of missing values (NAs = 171). Low birth weight was also excluded from analysis, as baby's weight was the response variable under consideration. The goal of this analysis is to create an algorithm that does exhaustive model selection and compare models based on different selection criterion.
\subsection{Model Selection Criterion}
\paragraph{}
The criterion used in this analysis were Akaike Information Criterion (AIC), Bayes Information Criterion (BIC) and adjusted R squared.
\newline
\newline
\begin{tabular}{|r|r|r|}
\hline
Akaike Information Criterion (AIC)&Bayes Information Criterion (BIC)&Adjusted R squared\\
\hline
 & &  \\
$= nlog(RSS/n) + 2(p+1)$&$= nlog(RSS/n) + (p+1)log(n)$&$= 1 - \frac{n-1}{n-p-1}(1-R^2)$\\
 & &  \\
\hline
\end{tabular}

\subsection{Model Selection Algorithm}
The code that implemented model selection does the following:
\begin{enumerate}
\item 
Creates a matrix where each $row_i$ corresponds to one possible combination of predictor variables
\item
Iterates through the rows of the matrix and fit a linear model, with $\emph{weight}$ as the response variable
\item
Stores the model summary coefficients and the AIC, BIC and adjusted $R^2$ values for each linear model
\item
Finds the 6 smallest AIC and BIC values as well as the 6 largest adjusted $R^2$ values
\item
Looks at diagnostic plots for model and individual variables
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Code involved in this analysis %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
<<echo=FALSE>>=
vars <- c("mage","mature","weeks","premie","visits","marital","gained","gender","habit","whitemom")
one <- combn(vars,1)
two <- combn(vars,2)
three <- combn(vars,3)
four <- combn(vars,4)
five <- combn(vars,5)
six <- combn(vars,6)
seven <- combn(vars,7)
eight <- combn(vars,8)
nine <- combn(vars,9)
ten <- combn(vars,10)

ones <- cbind(t(one),0,0,0,0,0,0,0,0,0)
twos <- cbind(t(two),0,0,0,0,0,0,0,0)
threes <- cbind(t(three),0,0,0,0,0,0,0)
fours <- cbind(t(four),0,0,0,0,0,0)
fives <- cbind(t(five),0,0,0,0,0)
sixes <- cbind(t(six),0,0,0,0)
sevens <- cbind(t(seven),0,0,0)
eights <- cbind(t(eight),0,0)
nines <- cbind(t(nine),0)
tens <- cbind(t(ten))


combos <- rbind(ones,twos,threes,fours,fives,sixes,sevens,eights,nines,tens)
mat <- matrix(NA, nrow=1023, ncol=3)
colnames(mat) <- c("AIC", "BIC","Adj R^2")
out <- list()

for (i in 1:1023){
  rowi0 <- combos[i,]
  rowi <- rowi0[rowi0 != 0]
  datai <- as.data.frame(cbind(births[,rowi],births[,"weight"]))
  names(datai) <- c(rowi,"weight")
  mi <- lm(datai$weight~.,data=datai)
  mat[i,] <- c(AIC(mi),BIC(mi),summary(mi)$adj.r.squared)
  out[[i]] <- summary(mi)$coef
  }
@
<<echo=FALSE,eval=FALSE>>=
# check that mat looks okay
head <- head(mat)
tail <- tail(mat)
# order of the linear models based on AIC (listed smallest to largest)
head(order(mat[,1]))
# order of the linear models based on BIC (listed smallest to largest)
head(order(mat[,2]))
# find the largest adjust r squared
tail(order(mat[,3]))

# check models based on AIC and BIC results
out[[833]]
out[[1012]]
@
<<echo=FALSE>>=
m833 <- lm(weight~weeks+premie+marital+gender+habit+whitemom,data=births)
m1012 <- lm(weight~weeks+premie+visits+marital+gained+gender+habit+whitemom,data=births)
@
<<echo=FALSE,eval=FALSE>>=
# AICs
AIC(m833)
AIC(m1012)

# BICs
BIC(m833)
BIC(m1012)

# plots
plot(m833)
plot(m1012)
@

\subsection{Results}
\paragraph{}
There were 1023 possible models to consider that were generated through the algorithm. After running through the code and looking at the three model criterion described above, there were two models of interest. Model 1012 had the smallest AIC and smallest BIC, while model 833 had the largest adjusted $R^2$. 

Because AIC and BIC values were in agreement that model 1012 was the best, and the adjusted $R^2$ values were similar for the two models, model 1012 was considered the best model using this method of selection. 

The following is a summary of the chosen model:
<<echo=FALSE>>=
out[[1012]]
@

Possible transformations were then explored for variables $\emph{weeks}$ and $\emph{visits}$, as both seem to have nonlinear relationships in the model. The transformed model was tested for curvature using the Tukey test ($p > .05$), and includes $premie$, $marital$, $gained$, $gender$, $habit$ and $whitemom$ as untransformed variables, and $weeks$ and $visits$ transformed. The transformed model also reduced AIC and BIC values and increased the adjusted $R^2$ coefficient (as compared to the original model).
<<echo=FALSE>>=
weeks2 <- (births[,"weeks"])^(1/8)
visits2 <- (births[,"visits"])^(1/6)
births2 <- cbind(births[,1:13],weeks2,visits2)
t1012 <- lm(weight~weeks+weeks2+premie+visits+visits2+marital+gained+gender+habit+whitemom,data=births2)
t833 <- lm(weight~weeks+weeks2+premie+marital+gender+habit+whitemom,data=births2)
@
<<echo=FALSE,eval=FALSE>>=
# model 1012: transformed vs original
AIC(t1012) # smaller AIC for model 1012
AIC(m1012)
BIC(t1012) # smaller BIC for model 1012
BIC(m1012)
summary(t1012)$adj.r.squared # higher adjusted R squared for model 1012
summary(m1012)$adj.r.squared

plot(t1012)
@

Possible interactions between pairs of variables in this model were also considered. The interaction between $premie$ and $weeks$ was considered the strongest of all the possible pairs and enhanced the model criterion further. That is, AIC and BIC values were reduced by adding this interaction, and adjusted $R^2$ was increased. The following table summarizes the criterion for the original models considered and the final model reached through transformations of $weeks$ and $visits$ and adding the interaction between $weeks$ and $premie$ to model 1012.
% final model summary
<<echo=FALSE>>=
mat2 <- matrix(NA, nrow=45, ncol=3)
colnames(mat2) <- c("AIC", "BIC","Adj R^2")
out2 <- list()

for (i in 1:45){
  rowi0 <- twos[i,]
  rowi <- rowi0[rowi0 != 0]
  datai <- as.data.frame(cbind(births[,rowi],births[,"weight"]))
  names(datai) <- c(rowi,"weight")
  mi <- lm(datai$weight~(datai[,1])*(datai[,2]),data=datai)
  mat2[i,] <- c(AIC(mi),BIC(mi),summary(mi)$adj.r.squared)
  out2[[i]] <- summary(mi)$coef
  }
@
<<echo=FALSE,eval=FALSE>>=
# order of AICs
head(order(mat2[,1]))
# order of BICs
head(order(mat2[,2]))
# order of adj R^2
tail(order(mat2[,3]))

# model 18 looks like the best possible model that considers an interaction
# model
out2[[18]]
# what are the variables
twos[18,]
# weeks and premie
@
<<echo=FALSE>>=
# try adding interaction to transformed model 1012
tI1012 <- lm(weight~weeks+weeks2+premie+visits+visits2+marital+gained+gender+habit+whitemom + weeks*premie,data=births2)
@
<<echo=FALSE,eval=FALSE>>=
# AIC comparison
AIC(tI1012)
AIC(t1012)
# AIC value is smaller in this model with the interaction
# BIC comparison
BIC(tI1012)
BIC(t1012)
# BIC value is smaller in this model with the interaction
# Adj R^2 comparison
summary(tI1012)$adj.r.squared
summary(t1012)$adj.r.squared
# Adj R^2 is larger in this model with the interaction
@
\begin{center}
\begin{tabular}{|r|r|r|r|}
\hline
Model&AIC&BIC&Adjusted $R^2$\\
\hline
Original 1012&2864.074&2912.767&0.475\\
Original 833&2972.751&3011.981&0.493\\
Final Model&\bf{2795.747}&\bf{2859.045}&\bf{0.513}\\
\hline
\end{tabular}
\end{center}
\subsection{Conclusions and Limitations}

Model selection is subjective and far from straightforward. Depending on what criterion one chooses to use, what the ultimate study goal is, and how exhaustive the model building process is, different models will be reached as appropriate. There is no one "best" model and often times criterion will disagree which models are more appropriate. The three plots below display fitted values against residuals for three separate models reached in this analysis. Differences are subtle and none are perfect.
<<echo=FALSE,fig.height=2.5, fig.align='center'>>=
par(mfrow = c(1, 3))
plot(t1012,which=1,caption="Transformed Model 1012")
plot(t833,which=1,caption="Transformed Model 833")
plot(tI1012,which=1,caption="Final Model")
@

There were multiple limitations of model selection found in this analysis. Transformations and interactions were considered after the model was selected. Intuitively, however, this should be done first. There is no guarantee that the model selected would have still been the most appropriate in comparison to the others had transformations and interactions been considered prior to iterating through all possible models. Another limitation found is that the predictor $visits$ is considered insignificant in the original model displayed above. Removing this variable, however, would give a different model (already considered in the algorithm) with significantly larger AIC and BIC values. Furthermore, in terms of the data, a linear model may not have been the best choice, as it appears constant variance may be violated in the final model reached in this analysis.

While this analysis did not reach a conclusive model to predict baby's weight or to have interpretable betas, it did explore the complexities of the exhaustive model selection process. Decisions on which model to build from are subjective and different criterion are used by different authors. In addition, models are built with the goal of the study in mind. By the end of this analysis, the model became less about the interpretation of the betas and more about trying to find a model that would best predict the response variable. Transformations, for example, would not have been considered if the betas were more important than prediction alone. Since the purpose here was not to find one or the other, both were considered in order to see how criterion values were affected. 

Overall, the number of weeks the mother was pregnant seemed to be the most important predictor of baby's weight. When analyzing the AIC, BIC and adjusted $R^2$ values for models containing a single predictor, the model based on $weeks$ is the most appropriate. Building the model up to be stronger according to the selection criterion only complicated the model and made it less approachable. If an author's goal is have a model that is easy to interpret and use, tinkering with the model make not be in the author's best interest.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%% Jon's Analysis %%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Variable Selection and Model Diagnostics: Jon Chiang}

\subsection{Introduction}
The all possible regressions approach actually looks at all possible combinations or subsets of each and all predictor variables and can fit the data according to a pre-selected criteria. Such criteria, proposed earlier, AIC and BIC each have a subsequent score, which allows us to rank our models accordingly. This analysis incorporated a step-wise regression in the forwards and backwards regression and an all possible regressions apporahc which uses all possible subsets of the pool of explanatory variables in order to fit a model.

All three model approaches concluded through AIC and BIC that weeks, gender, marital, gained and whitemom variables were suitable predictor variables. There was some discrepancy of female age, but the model did not show significant improvement. 


\subsection{Methods}
"Lowbirthweight" and the "premie" were not included in the model, because they are variables predicated on weeks and weight in categorical form. The leaps package in R was used to build the all-possible regression model. Pair-wise plots were used to study the variables and look for possible associations. Also, I used R to find leverage to find influential observations that may have skewed the data and subsequently plotted the residuals and cook's distance. 

\subsection{Residuals and Leverage}

Model Diagnostics. After fitting regession models we need to determine whether our model assumptions can be used before actually making an inference. We should look for violations and look for the consequential inferential procedures that would be void for these incorrect conclusions. Model Diagnostics combines both graphical and statistical methods. 
<<echo=FALSE, message=FALSE,fig=TRUE>>=

births2 = births
births2$lowbirthweight<-NULL
births2$premie<-NULL
Selection<-regsubsets(weight~fage+mage+weeks+gender+habit+whitemom+marital, data=births2,nbest=4) 
@
<<echo=FALSE, message=FALSE>>=
results<-(lm(weight ~ weeks+ + marital + gained + gender + habit + whitemom,births2))
results.table<-xtable(results)
@

\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
\hline
& Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
\hline
(Intercept) & -6.2423 & 0.4581 & -13.63 & 0.0000 \\
weeks & 0.3290 & 0.0120 & 27.51 & 0.0000 \\
maritalnot married & 0.2651 & 0.0757 & 3.50 & 0.0005 \\
gained & 0.0093 & 0.0024 & 3.81 & 0.0001 \\
gendermale & 0.3784 & 0.0690 & 5.49 & 0.0000 \\
habitsmoker & -0.3888 & 0.1048 & -3.71 & 0.0002 \\
whitemomwhite & 0.2121 & 0.0813 & 2.61 & 0.0092 \\
\hline
\end{tabular}
\end{table}


<<echo=FALSE, message=FALSE,fig.height=3.5,fig.width=6>>=
lev<-hat(model.matrix(results))
plot(lev,col="blue",main="Leverage")
#births2[lev>0.04,]
@

\textbf{Leverage Greater than 0.04}
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrrrr}
\hline
Observation & mature & weeks &  marital & gained & weight &habit&whitemom\\
\hline
942 & mature mom & 40 & married  & 35 & 8.63 & nonsmoker &white\\


\hline
\end{tabular}
\end{table}
 

<<echo=FALSE, message=FALSE,fig.height=3.5,fig.width=6>>=
#results.residuals<-resid(results)
#plot(results.residuals)

#r<-rstudent(results)
#plot(r)

cook<-cooks.distance(results)
plot(cook,ylab="Cook's Distances")
#births2[cook>0.02,]
@
\textbf{Cook's Distance Greater than 0.02}
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrrrr}
\hline
Observation & mature & weeks &  marital & gained & weight &habit&whitemom\\
\hline
70 & younger mom & 37 & married  & 25 & 6.19 &smoker&not white\\
665 & younger mom & 39 & not married & 21 & 7.88 &nonsmoker& white\\

\hline
\end{tabular}
\end{table}


\subsection{Discussion and Conclusion}

The dataset presented did not show any significant points of leverage. After plotting points in pair-wise variable scatter plots there were few outliers in the data. When conducting an all-possible regressions approach and/or step-wise regression it is imperative to use these models as guidelines and conduct more thorough thought into developing these models. Interactions must be accounted for and the P-values and R$\^2$ values may not be reliable in these cases. The models used, however, aligned very well with other approaches that analyzed the data. \newline Upon looking at the leverage, the outliered points were not very influential, which made using cook's distance less statistcally useful when intepreting the influence of the outliered observations.   

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%% Maritza's Analysis %%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Classification and Regression Trees (CART): Maritza Mallek}
\subsection{Introduction} Classification and Regression Trees (CARTs) are a nonparametric approach to regression. CARTs are generated through binary recursive partitioning, in which each potential independent variable used to build the model is tested to obtain the value at which the most meaningful split between two branches can be created. The rules can vary within and among R packages, but the goal is usually to minimize a value such as the sum of squared residuals, Gini index, or misclassification rate. The recursive aspect occurs as this process is repeated at each node of the tree, creating two new branches off each node until some predefined set of constraints are met, which stops the model. These constraints may include the number of observations in a node or marginal improvement in the value to be minimized.

Trees are popular because they are fairly intuitive to interpret, especially for non-statisticians, including in public health settings. At each node an equality is shown; for a given observation, if the inequality resolves as \textsc{true}, the reader follows the left branch. The alternative to CARTs is typically some form of parametric regression, such as GLM. For a doctor in a hospital, consulting a regression tree is much simpler than generating and interpreting a regression model. Because CARTs are nonparametric, the results do not explain why certain variable values result in the observed response, but in situations where researchers are interested in the likelihood and not necessarily interested in how to change an outcome, CARTs are a reasonable tool. They may be used for either exploratory or predictive data analysis.

\subsection{Methods: CART using R} Analysts running CART analysis in R typically use either the \verb|tree| or the \verb|rpart| package. The \verb|tree| package uses residuals, similarly to GLMs, while \verb|rpart| grows the tree using the Gini index of the data. In this analysis, the tree package was the primary tool. Also included are results using \verb|rpart| because better data visualization tools are available for this package, even if it is not as directly interpretable as the output from \verb|tree|.

The response variable selected for analysis by the group was \verb|weight|, also present in the dataset as the factored variable \verb|lowbirthweight|. The former is appropriate for regression tree analysis, while the latter is appropriate for classification trees. In this paper the biological significance of a 5.5 lb cutoff for low birth rate is accepted, and therefore \verb|lowbirthweight| is used. By default, observations with missing values are not used to build the tree. Consequently, only 800 observations are used to develop the tree. Standard practice in CART analysis is to first grow a tree, then ``prune" it by removing lower branches to avoid overfitting the data. Cross-validation is used to determine how much to prune a tree. The standard is 10-fold, and was employed here. In the first step of this analysis, all the available variables (the full model) were used to fit the data using the \verb|tree| package. Default parameters to constrain tree growth were accepted: minimum number of observations per child node = 5, smallest node size = 10, and within-node deviance parameter for nodes to be split = 0.01.


<<fullmodel, fig.height=5, fig.width=6, echo=FALSE, eval=FALSE>>=
form1 = lowbirthweight ~ fage + mage + mature + weeks + visits + marital + gained + gender + habit + whitemom
bt1 = tree(form1, data = births)
summary(bt1)
plot(bt1)
text(bt1, cex=0.7)
# Residual mean deviance:  0.3 = 237 / 790
bt1.cv = cv.tree(bt1)
bt1.p = prune.tree(bt1, best=3)
summary(bt1.p)
plot(bt1.p)
text(bt1.p, cex=1)
@

\subsection{Results}
\subsubsection{Classification tree analysis using the tree package} 
\paragraph{Investigation of the full model} Results from the initial analysis showed that \verb|weeks| is by far the most important predictor variable available. \verb|Gained|, \verb|marital|, and \verb|visits| were also used to construct the tree, which had 10 nodes, a residual mean deviance of 0.3, and a misclassification error rate of 0.0475. Cross-validation showed the best tree had just 2-3 nodes. Pruning based on this finding (refitting and constraining tree growth) at 3 nodes resulted in a tree in which \verb|weeks| was the only relevant predictor variable. The residual mean deviance and misclassification error rate increased slightly, to 0.363 and 0.0538, respectively.


<<prunedtree1, fig.height=3.1, fig.width=6, echo=FALSE, message=FALSE, fig.cap="Classification trees generated with the full model (left) and the alternative model (right). For the full model, 10-fold cross-validation was used to prune the tree, and the final result is pictured here. For the alternative model, pruning techniques reduced the model to 1 node (no tree) and so are not shown.">>=
form1 = lowbirthweight ~ fage + mage + mature + weeks + visits + marital + gained + gender + habit + whitemom
bt1 = tree(form1, data = births)
bt1.cv = cv.tree(bt1)
bt1.p = prune.tree(bt1, best=3)
par(mfrow = c(1, 2), mar=c(2,2,2,2))
plot(bt1.p)
text(bt1.p, cex=0.8, all=TRUE)
################
form2 = lowbirthweight ~ fage + mage  + marital + gender + habit + whitemom
bt2 = tree(form2, data=births)
plot(bt2)
text(bt2, cex=1, all=TRUE, pretty=8)
#bt3 = rpart(form2, data=births, method="class", control=rpart.control(minbucket=5, cp=0.001, maxcompete=7))
#fancyRpartPlot(bt3)

@

\paragraph{Investigation of the alternative model} While the finding of \verb|weeks| as the key predictor of low birth weight is reasonable, both logically and by an examination of associated metrics, it is not particularly interesting. A review of the variables used in the model shows that \verb|visits| and \verb|gained|, as well as \verb|weeks|, represent data recorded at the same time as \verb|weight|. Lacking information linked to gestational ages before birth, it may be disingenous to use these in a predictive framework. Given this reasoning, a new model was specified that omitted those variables, specified as:
\begin{verbatim}
lowbirthweight ~ fage + mage + marital + gender + habit + whitemom
\end{verbatim}

<<echo=FALSE, include=FALSE>>=
form2 = lowbirthweight ~ fage + mage  + marital + gender + habit + whitemom
bt2 = tree(form2, data=births)
@

<<echo=FALSE, include=FALSE>>=
bt2
summary(bt2)
plot(bt2)
text(bt2, cex=1, all=TRUE, pretty=8)
#plot(cv.tree(bt2))
@

<<echo=FALSE, include=FALSE, fig.height=4>>=
bt2.adj = tree(form2, data=births, control=tree.control(1000, mincut=5, minsize=10, mindev=0.005))
summary(bt2.adj)
plot(bt2.adj)
text(bt2.adj, cex=.6, pretty=10)

bt2.adj.cv = cv.tree(bt2.adj)
bt2.adj.p = prune.tree(bt2.adj, best=which.min(bt2.adj.cv$dev))
plot(bt2.adj.p)
text(bt2.adj.p, cex=1, all=TRUE, pretty=10)
@

Running the classification tree function using the new model produced a tree with just three nodes using the variable \verb|marital|. However, none of the terminal branches included a set of observations that are more than 50\% low birth weight. Thus this model always predicts ``not low'' birth weight. Reducing the stopping criteria allows the tree to grow more branches, and is one way to force a tree to better fit a dataset. In this analysis, the within-node deviance (\verb|mindev|) was halved. As a result, all variables but \verb|gender| were used to produce the tree, which had 18 terminal nodes, a residual mean deviance of 0.5643, and a misclassification error rate of 0.09674. One of the terminal nodes predicted low birth weight for the observations at that node.

\subsubsection{Classification tree analysis using the rpart package} The \verb|rpart| package was briefly explored to further examine the data. The reduced model was used and the default settings regulating tree growth were again adjusted simply to obtain a tree with any branches at all. The minimum number of observations in a terminal node was reduced to 5 and the complexity parameter was reduced to 0.001 (an order of magnitude less than the default). Results differed from those associated with the \verb|tree| package since splits were based on the Gini index. All predictor variables had some importance, although \verb|mage| and \verb|marital| were the most influential. Again, the difficulty of producing trees that isolated low birth weight suggests that the predictor variables used are not necessarily significant, especially for prediction.


<<echo=FALSE, include=FALSE, results='hide'>>=
bt3 = rpart(form2, data=births, method="class", control=rpart.control(minbucket=5, cp=0.001, maxcompete=7))
printcp(bt3)
plotcp(bt3)
print(bt3)
summary(bt3)
plot(bt3, uniform=F, main="Classification Tree for Low Birth Weight")
text(bt3, use.n=TRUE, all=TRUE, pretty=10, cex=0.6)
fancyRpartPlot(bt3)

cparam = bt3$cptable[which.min(bt3$cptable[,"xerror"]),"CP"]

@

\subsection{Discussion and Conclusions}
\subsubsection{Classification Trees vs. GLM}
<<echo=FALSE, include=FALSE, results='hide'>>=
# compare tree to second-order GLM
glm1 = glm(form2, data=births, family=binomial)
summary(glm1)
# Residual deviance: 457.24  on 791  degrees of freedom
457.24/791
@
The full model was analyzed in R as a generalized linear model (GLM) and logistic regression. Predictor variables hospital \verb|visits| and weight \verb|gained| were significant at the 0.01 level, while smoking and white mom were significant at the 0.1 level. All other variables did not show significance at the 0.1 or smaller level. The classification tree had slightly lower residual deviance than the GLM (0.5014 and 0.5781, respectively). Statistically, the difference between them falls into a subjective zone. While trees are theoretically easy to use, in the case of the selected dataset and response variable, using a tree may generate confusion since it did not make a strong prediction for low birth weight.

Classification trees were of mixed use in exploring this dataset. Four of the predictor variables in the initial model were needed to segment the data. Results showed that none of the recorded variables were particularly well-suited for predicting low birth weight, but any explanations are simple speculation. The pruned, cross-validated tree composed using the full model had only 3 nodes and only one variable was used to create the tree. The trees make clear that \verb|weeks| is a key variable, this seems an obvious result. The second model suggests that further exploration of the associated implications of mother's marital status may lead to variables with some predictive power, which the dataset currently lacks as far as can be detected within the classification tree framework.

\subsubsection{An Interesting Negative Result} This analysis produced an interesting negative result: none of the provided variables are highly significant predictors of low birth weight, especially when discounting variables measured at the same time as birth weight, as in the alternative model. No obvious interactions between variables were revealed through the analysis. To some extent, this is a disappointing outcome because a set of key predictor variables for this attribute was not found. However, the results may be useful because they suggest that additional variables or additional data points over time are needed to understand the relationship between the habits and practices of mothers and health outcomes like low birth weight. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%% Steele's Analysis %%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Missing Data: Steele Valenzuela}
\subsection{Introduction} Tackling missing data was born out of the frustration of having missing data in the Titanic Competition as well as running into issues with basic simple linear regression models.  Simply put, R's behavior when dealing with missing data is a pain in the arse.
\paragraph{} According to online and statistical literature, it appears that Little \& Rubin, 1987, cavaliered methods of placing data into missing values, or in other words, the process of \emph{imputation}.  Since then, statisticians have pulled their hair out over ways of dealing with missing data as well as innovated the field with new and promising methods, one of which I will show in later on.  Ultimately, this section will tackle three basic ideas, \textbf{finding}, \textbf{visualizing}, and \textbf{analyzing} missing data.

\subsection{Finding Missing Data} Basic \textbf{NA} functions are really useful in finding missing values.  The functions below will find the total number of missing values and the total number of rows that do not contain missing values.
<<echo=TRUE>>=
missing <- is.na(ncbirths) #stores total number of TRUEs that indicates NA's
sum(missing) #total number of NA's in dataset

ncbirths.new <- na.omit(ncbirths) #na.omit omits any rows with data points NA
nrow(ncbirths.new) #nrow counts the number of rows in our new subset
@
Furthermore, if one wanted to meticulously examine each row that contains missing data, the following function is quite useful.
<<echo=TRUE, results='hide'>>=
ncbirths[!complete.cases(ncbirths),] #this function will view all 200 rows of missing data
head(ncbirths[!complete.cases(ncbirths),], 3) #viewing the first three rows
@
Let us move onto visualizing missing data.

\subsection{Visualizing Missing Data}
\emph{Please note, if wanting an in-depth analysis of visual aids for missing data, please see lab exercise or individual analysis.} The first basic function in visualizing missing data comes from the \textbf{ggplot2} package as shown below.  This function will only quantify the missing values, but it is really bright, useful, and quick.
<<echo=TRUE, fig.height=4, fig.width=4, message=FALSE>>=
ggmissing(ncbirths, avoid="stack", order=TRUE, missing.only=TRUE) #see ?ggmissing for arguments as they are quite basic
@
The next visual aid is a scatterplot, that is tricky to grasp its meaning at first, but is best understood as displaying missing data \textbf{in the margins}.
<<echo=FALSE, fig.width=4, fig.height=4>>=
min.age <- with(ncbirths, min(fage, na.rm=T)) #na.rm must be specified or the minimum value will default to NA
tenprcnt.min.age <- (90/100)*min.age #the minimum age is 14 and 90% is 12.6
ncbirths$imputed.fage <- impute(ncbirths$fage, fun=tenprcnt.min.age)
qplot(imputed.fage, mage, data=ncbirths, geom=c("point", "jitter"), color=I("purple"), size=I(3), alpha=I(.4))+scale_y_continuous(breaks=seq(10, 50, 5))+scale_x_continuous(breaks=seq(10,50,5))
@
As aforementioned, this is a tricky plot, but the techniques utilized are simple.  Using the \emph{Hmisc} package and a simple imputation function, all of the missing values for the variable \textbf{fage} are imputed with a value that is ten percent lower than the minimum value.  We see that the minimum value for \textbf{fage} is 14, and ten percent lower is 12.6.  Essentially, the distribution of \textbf{fage} missing values can be seen against \textbf{mage}. 

\subsection{Analyzing Missing Data}
For the analysis of missing data, we need two items, the group's original model and the imputed model.  Let us run the original model our group has chosen below.
<<echo=TRUE >>=
group.model <- lm(weight~fage+mage+weeks+visits+marital+gained+gender+habit+whitemom, data=ncbirths)
summary(group.model)
@
From the summary of our group model, we see that 200 rows were omitted due to missing values.  We will now implement the Amelia package and its obvious function \textbf{amelia} to create an imputed dataset.
<<echo=TRUE, message=FALSE, results='hide'>>=
set.seed(690) #let's set the seed so this example is reproducible.
imp.ncbirths <- amelia(x=ncbirths, m=10, idvars="imputed.fage", noms=c("mature", "premie", "lowbirthweight", "marital", "gender", "habit", "whitemom"))
@
Next, let us analyze the data with the Zelig package and its obvious function \textbf{zelig}.
<<echo=TRUE, results='hide'>>=
imp.group.model <- zelig(weight~fage+mage+weeks+visits+marital+gained+gender+habit+whitemom, 
data=imp.ncbirths$imputations, model="ls") 
#it is semantically styled similarly to the *lm* function
@
<<echo=FALSE>>=
summary(imp.group.model)
@
We may compare each of the coefficients of the original group model and the imputed model, but rather, a visual is preferred to handle this much information.  If our model contained a 2, 3, or even 4 variables, it may be possible to manually compare models, but for now, we will not.  The visual aid is shown below. 
<<echo=FALSE, fig.height=6, fig.width=6, results='hide'>>=
b.out<-NULL #empty cells for extracting beta coefficients 
se.out<-NULL #and standard errors

#for loop that will draw out said values of imputed model
for(i in 1:imp.ncbirths$m) { # Replicate the model on each imputed dataset
ols.out <- lm(weight~fage+mage+weeks+visits+marital+gained+gender+habit+whitemom, #imputed model
data = imp.ncbirths$imputations[[i]])
b.out <- rbind(b.out, ols.out$coef)
se.out <- rbind(se.out, coef(summary(ols.out))[,2])
}

combined.results <- mi.meld(q=b.out, se=se.out) #an Amelia function made for the above 'for loop'
combined.results #final product that is easier to read

lwdFrame <- data.frame(Variable = rownames(summary(group.model)$coef),
Coef = summary(group.model)$coef[, 1],
SE = summary(group.model)$coef[, 2],
Method = "listwiseDelete")
midFrame <- data.frame(Variable = colnames(combined.results$q),
Coef = c(combined.results$q),
SE = c(combined.results$se),
Method = "imputation")
resultFrame <- data.frame(rbind(lwdFrame, midFrame))

zp1 <- ggplot(resultFrame, aes(colour = Method))

zp1 <- zp1 + geom_hline(yintercept = 0, colour = gray(1/2), lty = 2)

zp1 <- zp1 + geom_linerange(aes(x = Variable, ymin = Coef - SE*1,
ymax = Coef + SE*1),
lwd = 1, position = position_dodge(width = 1/2))

zp1 <- zp1 + geom_pointrange(aes(x = Variable, y = Coef,
ymin = Coef - SE*2, ymax = Coef + SE*2),
lwd = 1/2, position = position_dodge(width = 1/2),
shape = 21, fill = "WHITE")

zp1 <- zp1 + coord_flip() + theme_bw()

zp1 <- zp1 + ggtitle("Comparing coefficient estimates by missing data methods")

print(zp1)
@
So, let's walk through the basic characteristics of this plot.  The y-axis displays names of our variables in the model, the x-axis displays the values of the beta coefficients of the respective variables, the red figures display our orginal listwise deletion model \(200 rows were omitted\), and the blue figures display our imputed data using the Amelia package.  If you look closely at the red and blue figures, there is a short dark shade and a longer lighter shade.  This displays 1 and 2 standard deviations from the coefficient estimate, respectively.  Visible and slight differences may be seen for the \emph{intercept} and the variables \textbf{gender}, \textbf{habit}, \textbf{married}, and \textbf{whitemom}. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%% 1 Page Discussion/Conclusions %%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Group Discussion and Conclusions}
\subsection{Public Health Impact Discussion}

As researchers and collaborators explore relationships between habits and practices of expectant mothers and the birth of their children, it is imperative to maximize the well-being of expectant mothers and their babies. This is especially important, because premature babies have a much higher mortality rate. Developing research has indicated that there are prenatal influences on obesity, which include the mother's smoking habits, mother's weight gain, and the blood sugar levels during pregnancy. It is critical for biostaticians, clinical researchers, Public Health members and Doctors to collaborate on gathering data and teasing out important causes of maladaptive health. With an emphasis on prevention, our regression meta-study hopes to find more predictor variables for baby weight, but also discerning whether or not there is a strong likelihood for a premature birth.

\subsection{Findings}

The dataset in it of itself showed that weeks was the strongest predictor of weight for the babies. The multitude of techniques for model-building collaborated with this notion and it would make intuitive sense that more developed babies in the womb would have a healthier weight than babies born prematurely. In terms of leverage, the dataset did not show any significant observations that would influence the model significantly. 




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Summary stats needed for table of variables %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Use for number of missing values in each distribution
<<echo=FALSE,eval=FALSE>>=
summary(births)
@

% FATHERS AGE CONFIDENCE INTERVALS:
<<echo=FALSE,eval=FALSE>>=

# Mean and variance
mean(fage,na.rm=TRUE)
var(fage,na.rm=TRUE)

# calculation of n = (number of values in fage) - (number NAs)
1000-171


# 95 percent CI for mean
# lower bound, upper bound
mean(fage,na.rm=TRUE) - qnorm(.975)*(sd(fage,na.rm=TRUE)/sqrt(829))
mean(fage,na.rm=TRUE) + qnorm(.975)*(sd(fage,na.rm=TRUE)/sqrt(829))

# 95 percent CI for variance
# lower bound, upper bound
((829-1)*var(fage,na.rm=TRUE))/qchisq(0.975,df=(829-1))
((829-1)*var(fage,na.rm=TRUE))/qchisq(0.025,df=(829-1))

@


% MOTHERS AGE CONFIDENCE INTERVALS:
<<echo=FALSE,eval=FALSE>>=

# Mean and variance
mean(mage,na.rm=TRUE)
var(mage,na.rm=TRUE)

# No missing values in mage -> n=1000

# 95 percent CI for mean
# lower bound, upper bound
mean(mage,na.rm=TRUE) - qnorm(.975)*(sd(mage,na.rm=TRUE)/sqrt(1000))
mean(mage,na.rm=TRUE) + qnorm(.975)*(sd(mage,na.rm=TRUE)/sqrt(1000))

# 95 percent CI for variance
# lower bound, upper bound
((1000-1)*var(mage,na.rm=TRUE))/qchisq(0.975,df=(1000-1))
((1000-1)*var(mage,na.rm=TRUE))/qchisq(0.025,df=(1000-1))

@


% WEEKS CONFIDENCE INTERVALS:
<<echo=FALSE,eval=FALSE>>=

# Mean and variance
mean(weeks,na.rm=TRUE)
var(weeks,na.rm=TRUE)

# calculation of n = (number of values in fage) - (number NAs)
1000-2


# 95 percent CI for mean
# lower bound, upper bound
mean(weeks,na.rm=TRUE) - qnorm(.975)*(sd(weeks,na.rm=TRUE)/sqrt(998))
mean(weeks,na.rm=TRUE) + qnorm(.975)*(sd(weeks,na.rm=TRUE)/sqrt(998))

# 95 percent CI for variance
# lower bound, upper bound
((998-1)*var(weeks,na.rm=TRUE))/qchisq(0.975,df=(998-1))
((998-1)*var(weeks,na.rm=TRUE))/qchisq(0.025,df=(998-1))

@

% VISITS CONFIDENCE INTERVALS:
<<echo=FALSE,eval=FALSE>>=

# Mean and variance
mean(visits,na.rm=TRUE)
var(visits,na.rm=TRUE)

# calculation of n = (number of values in fage) - (number NAs)
1000-9


# 95 percent CI for mean
# lower bound, upper bound
mean(visits,na.rm=TRUE) - qnorm(.975)*(sd(visits,na.rm=TRUE)/sqrt(991))
mean(visits,na.rm=TRUE) + qnorm(.975)*(sd(visits,na.rm=TRUE)/sqrt(991))

# 95 percent CI for variance
# lower bound, upper bound
((991-1)*var(visits,na.rm=TRUE))/qchisq(0.975,df=(991-1))
((991-1)*var(visits,na.rm=TRUE))/qchisq(0.025,df=(991-1))

@

% GAINED CONFIDENCE INTERVALS:
<<echo=FALSE,eval=FALSE>>=

# Mean and variance
mean(gained,na.rm=TRUE)
var(gained,na.rm=TRUE)

# calculation of n = (number of values in fage) - (number NAs)
1000-27


# 95 percent CI for mean
# lower bound, upper bound
mean(gained,na.rm=TRUE) - qnorm(.975)*(sd(gained,na.rm=TRUE)/sqrt(973))
mean(gained,na.rm=TRUE) + qnorm(.975)*(sd(gained,na.rm=TRUE)/sqrt(973))

# 95 percent CI for variance
# lower bound, upper bound
((973-1)*var(gained,na.rm=TRUE))/qchisq(0.975,df=(973-1))
((973-1)*var(gained,na.rm=TRUE))/qchisq(0.025,df=(973-1))

@

% WEIGHT CONFIDENCE INTERVALS:
<<echo=FALSE,eval=FALSE>>=

# Mean and variance
mean(weight,na.rm=TRUE)
var(weight,na.rm=TRUE)

# calculation of n = (number of values in fage) - (number NAs)
1000-0


# 95 percent CI for mean
# lower bound, upper bound
mean(weight,na.rm=TRUE) - qnorm(.975)*(sd(weight,na.rm=TRUE)/sqrt(1000))
mean(weight,na.rm=TRUE) + qnorm(.975)*(sd(weight,na.rm=TRUE)/sqrt(1000))

# 95 percent CI for variance
# lower bound, upper bound
((1000-1)*var(weight,na.rm=TRUE))/qchisq(0.975,df=(1000-1))
((1000-1)*var(weight,na.rm=TRUE))/qchisq(0.025,df=(1000-1))

@


\end{document}
