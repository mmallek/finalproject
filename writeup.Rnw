\documentclass[11pt]{article}
%\usepackage{geometry}                
%\geometry{letterpaper, top=1.5cm, left=2cm} 
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
\usepackage{url}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{ textcomp }
\usepackage{lscape}
\usepackage{multirow}



\renewcommand{\familydefault}{cmss}

\title{Group 2 Final Project}
\author{PUBHLTH 690R: Statistical Modeling and Data Visualization\\
        Members: Jon Chiang, Maritza Mallek, Sara Nu\~nez, Steele Valenzuela}


\begin{document}
\maketitle

\tableofcontents

\newpage
% Load libraries
<<echo=FALSE, message=FALSE>>=
require(ggplot2)
require(GGally)
require(RCurl)
require(knitr)
theme_set(theme_bw())
#required for Jonathan
require(leaps)
require(xtable)
# required for Maritza
require(rpart)
require(tree)
require(rattle)
require(rpart.plot)
@
% Load data
<<echo=FALSE>>=
births = getURL("https://raw.githubusercontent.com/mmallek/finalproject/master/ncbirths.txt",ssl.verifypeer=FALSE, followlocation=1L, .opts=curlOptions(sslversion=3))
births = read.table(text=births, sep='\t', header=TRUE)
attach(births)
@


% The following is a multiplot function to condense the qplots
<<echo=FALSE>>=
# multiplot function
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  require(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
@

\section{Introduction}
This dataset was acquired from OpenIntro.org's free collection. According to the metadata, `ncbirths' was released in 2004 by North Carolina. This data set has been of interest to medical researchers who are studying the relation between habits and practices of expectant mothers and the birth of their children. The data provided by OpenIntro is a random sample of 1,000 cases from this data set.

Of the 13 variables presented in the dataset, there are several options for thinking about predictors vs. response variables. Some of these are clearly predictors: \verb|fage|, \verb|mage|, \verb|marital|, \verb|habit|, \verb|gender|, \verb|whitemom|. Others could be considered either predictors or responses: \verb|weeks|, \verb|premie|, \verb|visits|, \verb|gained|, \verb|weight| (or \verb|lowbirthweight|). Based on the dataset description, which states that the research was exploring "habits and practices of expectant mothers," our inference is that habits and practices refer to weight gained by the mother and the smoking status of the mother (possibly marital status as well). The most likely responses are (hospital) \verb|visits|, (gestational) \verb|weeks| (related to \verb|premie|), and (baby's birth) \verb|weight| (related to \verb|lowbirthweight|). An additional key characteristic of this dataset is that 6 of the variables are pairs of continuous and categorical data (see Table \ref{table:factors}).

One of the main challenges from this dataset is that we do not have data synced to a gestational age other than at term. The values for \verb|visits|, \verb|weeks|, \verb|weight|, and \verb|gained| are all collected at birth. While it makes sense to include all variables in any exploratory analysis of relationships among these variables, the value of any of these as prediction terms is problematic because they are collected at the end of the pregancy.

We are most interested in the baby's weight at birth, which we will examine in both its continuous and factored format. This is our initial, full model:
<<eval=FALSE>>=
lm(weight ~ mage + fage + weeks + visits + gained + habit + whitemom + marital + gender)
glm(lowbirthweight ~ mage + fage + weeks + visits + gained + habit + whitemom + marital + gender, family=binomial)
@

\begin{landscape}

\begin{table}
\centering
\begin{tabular}{lllll}
\hline
Continuous Variable & Two-level Factor & Equation with factor labels & Observations & NAs\\
\hline
mage & mature & younger mom $< 35 \text{ years}<=$ mature mom & 867/133 & 0\\
weeks & premie & premie $< 37 \text{ weeks}<= $ full term & 846/152 & 2\\
weight & lowbirthweight & low $<= 5.5 \text{ pounds}<$ not low & 111/889 & 0\\
n/a & marital & married OR not married & 386/613 & 1\\
n/a & whitemom & white OR not white & 714/284 & 2 \\
n/a & habit & nonsmoker OR smoker & 873/126 & 1 \\
n/a & gender & female OR male & 503/497 & 0 \\
\end{tabular}
\caption{Factored variables.
\label{table:factors}}
\end{table}



\vspace{3cm}
% To build this table I just went through Steele's paragraphs in "Summary of variables" and converted it to numbers. -M

% to size and wrap a column in a table: p{4cm}
\begin{table}
\centering
\begin{tabular}{ccccccccc}
\hline
Variable & \multirow{2}{*}{\parbox{2cm}{Variable Definitions}}  & Min & Median & Mean & Max & \multirow{2}{*}{\parbox{2cm}{Missing Values}} & 95\% CI for Mean & 95\% CI for Variance\\
 & & & & & & & & \\
\hline
fage & father's age & 14 & 30 & 30.26 & 55 & 171 & (29.7953, 30.71616) & (41.6428, 50.49614)\\
mage & mother's age & 13 & 27 & 27 & 50 & 0 & (26.61489, 27.38511) & (35.4345, 42.23142) \\
weeks & gestational age & 20 & 39 & 38.33 & 45 & 2 & (38.15279, 38.51655) & (7.886806,9.40128) \\
visits & hospital visits & 0 & 12.0 & 12.1 & 30 & 9 & (11.85871,12.35118) & (14.35011,17.11633)\\
%gained & \multirow{2}{*}{weight gained} & 0 & 30 & 30.33 & 85 & 27 \\
%&  by mother & & & & & \\
gained & \multirow{2}{*}{\parbox{3cm}{weight gained by mother}} & 0 & 30 & 30.33 & 85 & 27 & (29.43097,31.22063) & (185.9254,222.1265) \\
 & & & & & & & & \\
weight & birth weight of baby & 1 & 7.31 & 7.101 & 11.750 & 0 & (7.007482,7.194518) & (2.08949,2.490288)\\
\end{tabular}
% This caption is dumb but I am not sure what to put here.
\caption{Continuous variables}
\label{table:continuous}
\end{table}

\end{landscape}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%% Sara's Analysis %%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Model Selection Analysis: Sara Nu\~nez}
\subsection{Methods}
\paragraph{}
This analysis of the $\emph{NCbirths}$ data is concerned with the process of model selection and the differences between several selection criterion. In order to evaluate possible models, code was developed that implements model selection based on all possible subsets of 10 of the 12 possible predictor variables in the dataset. Father's age was not considered in this analysis, as it had a large number of missing values (NAs = 171). Low birth weight was also excluded from analysis, as baby's weight was the response variable under consideration. The goal of this analysis is to create an algorithm that does exhaustive model selection and compare models based on different selection criterion.
\subsection{Model Selection Criterion}
\paragraph{}
The criterion used in this analysis were Akaike Information Criterion (AIC), Bayes Information Criterion (BIC) and adjusted R squared.
\newline
\newline
\begin{tabular}{|r|r|r|}
\hline
Akaike Information Criterion (AIC)&Bayes Information Criterion (BIC)&Adjusted R squared\\
\hline
 & &  \\
$= nlog(RSS/n) + 2(p+1)$&$= nlog(RSS/n) + (p+1)log(n)$&$= 1 - \frac{n-1}{n-p-1}(1-R^2)$\\
 & &  \\
\hline
\end{tabular}

\subsection{Model Selection Algorithm}
The code that implemented model selection does the following:
\begin{enumerate}
\item 
Creates a matrix where each $row_i$ corresponds to one possible combination of predictor variables
\item
Iterates through the rows of the matrix and fit a linear model, with $\emph{weight}$ as the response variable
\item
Stores the model summary coefficients and the AIC, BIC and adjusted $R^2$ values for each linear model
\item
Finds the 6 smallest AIC and BIC values as well as the 6 largest adjusted $R^2$ values
\item
Looks at diagnostic plots for model and individual variables
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Code involved in this analysis %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
<<echo=FALSE>>=
vars <- c("mage","mature","weeks","premie","visits","marital","gained","gender","habit","whitemom")
one <- combn(vars,1)
two <- combn(vars,2)
three <- combn(vars,3)
four <- combn(vars,4)
five <- combn(vars,5)
six <- combn(vars,6)
seven <- combn(vars,7)
eight <- combn(vars,8)
nine <- combn(vars,9)
ten <- combn(vars,10)

ones <- cbind(t(one),0,0,0,0,0,0,0,0,0)
twos <- cbind(t(two),0,0,0,0,0,0,0,0)
threes <- cbind(t(three),0,0,0,0,0,0,0)
fours <- cbind(t(four),0,0,0,0,0,0)
fives <- cbind(t(five),0,0,0,0,0)
sixes <- cbind(t(six),0,0,0,0)
sevens <- cbind(t(seven),0,0,0)
eights <- cbind(t(eight),0,0)
nines <- cbind(t(nine),0)
tens <- cbind(t(ten))


combos <- rbind(ones,twos,threes,fours,fives,sixes,sevens,eights,nines,tens)
mat <- matrix(NA, nrow=1023, ncol=3)
colnames(mat) <- c("AIC", "BIC","Adj R^2")
out <- list()

for (i in 1:1023){
  rowi0 <- combos[i,]
  rowi <- rowi0[rowi0 != 0]
  datai <- as.data.frame(cbind(births[,rowi],births[,"weight"]))
  names(datai) <- c(rowi,"weight")
  mi <- lm(datai$weight~.,data=datai)
  mat[i,] <- c(AIC(mi),BIC(mi),summary(mi)$adj.r.squared)
  out[[i]] <- summary(mi)$coef
  }
@
<<echo=FALSE,eval=FALSE>>=
# check that mat looks okay
head <- head(mat)
tail <- tail(mat)
# order of the linear models based on AIC (listed smallest to largest)
head(order(mat[,1]))
# order of the linear models based on BIC (listed smallest to largest)
head(order(mat[,2]))
# find the largest adjust r squared
tail(order(mat[,3]))

# check models based on AIC and BIC results
out[[833]]
out[[1012]]
@
<<echo=FALSE>>=
m833 <- lm(weight~weeks+premie+marital+gender+habit+whitemom,data=births)
m1012 <- lm(weight~weeks+premie+visits+marital+gained+gender+habit+whitemom,data=births)
@
<<echo=FALSE,eval=FALSE>>=
# AICs
AIC(m833)
AIC(m1012)

# BICs
BIC(m833)
BIC(m1012)

# plots
plot(m833)
plot(m1012)
@

\subsection{Results}
\paragraph{}
There were 1023 possible models to consider that were generated through the algorithm. After running through the code and looking at the three model criterion described above, there were two models of interest. Model 1012 had the smallest AIC and smallest BIC, while model 833 had the largest adjusted $R^2$. 

Because AIC and BIC values were in agreement that model 1012 was the best, and the adjusted $R^2$ values were similar for the two models, model 1012 was considered the best model using this method of selection. 

The following is a summary of the chosen model:
<<echo=FALSE>>=
out[[1012]]
@

Possible transformations were then explored for variables $\emph{weeks}$ and $\emph{visits}$, as both seem to have nonlinear relationships in the model. The transformed model was tested for curvature using the Tukey test ($p > .05$), and includes $premie$, $marital$, $gained$, $gender$, $habit$ and $whitemom$ as untransformed variables, and $weeks$ and $visits$ transformed. The transformed model also reduced AIC and BIC values and increased the adjusted $R^2$ coefficient (as compared to the original model).
<<echo=FALSE>>=
weeks2 <- (births[,"weeks"])^(1/8)
visits2 <- (births[,"visits"])^(1/6)
births2 <- cbind(births[,1:13],weeks2,visits2)
t1012 <- lm(weight~weeks+weeks2+premie+visits+visits2+marital+gained+gender+habit+whitemom,data=births2)
t833 <- lm(weight~weeks+weeks2+premie+marital+gender+habit+whitemom,data=births2)
@
<<echo=FALSE,eval=FALSE>>=
# model 1012: transformed vs original
AIC(t1012) # smaller AIC for model 1012
AIC(m1012)
BIC(t1012) # smaller BIC for model 1012
BIC(m1012)
summary(t1012)$adj.r.squared # higher adjusted R squared for model 1012
summary(m1012)$adj.r.squared

plot(t1012)
@

Possible interactions between pairs of variables in this model were also considered. The interaction between $premie$ and $weeks$ was considered the strongest of all the possible pairs and enhanced the model criterion further. That is, AIC and BIC values were reduced by adding this interaction, and adjusted $R^2$ was increased. The following table summarizes the criterion for the original models considered and the final model reached through transformations of $weeks$ and $visits$ and adding the interaction between $weeks$ and $premie$ to model 1012.
% final model summary
<<echo=FALSE>>=
mat2 <- matrix(NA, nrow=45, ncol=3)
colnames(mat2) <- c("AIC", "BIC","Adj R^2")
out2 <- list()

for (i in 1:45){
  rowi0 <- twos[i,]
  rowi <- rowi0[rowi0 != 0]
  datai <- as.data.frame(cbind(births[,rowi],births[,"weight"]))
  names(datai) <- c(rowi,"weight")
  mi <- lm(datai$weight~(datai[,1])*(datai[,2]),data=datai)
  mat2[i,] <- c(AIC(mi),BIC(mi),summary(mi)$adj.r.squared)
  out2[[i]] <- summary(mi)$coef
  }
@
<<echo=FALSE,eval=FALSE>>=
# order of AICs
head(order(mat2[,1]))
# order of BICs
head(order(mat2[,2]))
# order of adj R^2
tail(order(mat2[,3]))

# model 18 looks like the best possible model that considers an interaction
# model
out2[[18]]
# what are the variables
twos[18,]
# weeks and premie
@
<<echo=FALSE>>=
# try adding interaction to transformed model 1012
tI1012 <- lm(weight~weeks+weeks2+premie+visits+visits2+marital+gained+gender+habit+whitemom + weeks*premie,data=births2)
@
<<echo=FALSE,eval=FALSE>>=
# AIC comparison
AIC(tI1012)
AIC(t1012)
# AIC value is smaller in this model with the interaction
# BIC comparison
BIC(tI1012)
BIC(t1012)
# BIC value is smaller in this model with the interaction
# Adj R^2 comparison
summary(tI1012)$adj.r.squared
summary(t1012)$adj.r.squared
# Adj R^2 is larger in this model with the interaction
@
\begin{center}
\begin{tabular}{|r|r|r|r|}
\hline
Model&AIC&BIC&Adjusted $R^2$\\
\hline
Original 1012&2864.074&2912.767&0.475\\
Original 833&2972.751&3011.981&0.493\\
Final Model&\bf{2795.747}&\bf{2859.045}&\bf{0.513}\\
\hline
\end{tabular}
\end{center}
\subsection{Conclusions and Limitations}

Model selection is subjective and far from straightforward. Depending on what criterion one chooses to use, what the ultimate study goal is, and how exhaustive the model building process is, different models will be reached as appropriate. There is no one "best" model and often times criterion will disagree which models are more appropriate. The three plots below display fitted values against residuals for three separate models reached in this analysis. Differences are subtle and none are perfect.
<<echo=FALSE,fig.height=2.5, fig.align='center'>>=
par(mfrow = c(1, 3))
plot(t1012,which=1,caption="Transformed Model 1012")
plot(t833,which=1,caption="Transformed Model 833")
plot(tI1012,which=1,caption="Final Model")
@

There were multiple limitations of model selection found in this analysis. Transformations and interactions were considered after the model was selected. Intuitively, however, this should be done first. There is no guarantee that the model selected would have still been the most appropriate in comparison to the others had transformations and interactions been considered prior to iterating through all possible models. Another limitation found is that the predictor $visits$ is considered insignificant in the original model displayed above. Removing this variable, however, would give a different model (already considered in the algorithm) with significantly larger AIC and BIC values. Furthermore, in terms of the data, a linear model may not have been the best choice, as it appears constant variance may be violated in the final model reached in this analysis.

While this analysis did not reach a conclusive model to predict baby's weight or to have interpretable betas, it did explore the complexities of the exhaustive model selection process. Decisions on which model to build from are subjective and different criterion are used by different authors. In addition, models are built with the goal of the study in mind. By the end of this analysis, the model became less about the interpretation of the betas and more about trying to find a model that would best predict the response variable. Transformations, for example, would not have been considered if the betas were more important than prediction alone. Since the purpose here was not to find one or the other, both were considered in order to see how criterion values were affected. 

Overall, the number of weeks the mother was pregnant seemed to be the most important predictor of baby's weight. When analyzing the AIC, BIC and adjusted $R^2$ values for models containing a single predictor, the model based on $weeks$ is the most appropriate. Building the model up to be stronger according to the selection criterion only complicated the model and made it less approachable. If an author's goal is have a model that is easy to interpret and use, tinkering with the model make not be in the author's best interest.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%% Jon's Analysis %%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Model Selection and Diagnostics: Jonathan Chiang}
\subsection{Introduction}
The all possible regressions approach actually looks at all possible combinations or subsets of each and all predictor variables and can fit the data according to a pre-selected criteria. Such criteria, proposed earlier, AIC and BIC each have a subsequent score, which allows us to rank our models accordingly. 
\subsection{Figures and Tables}
<<echo=FALSE, message=FALSE,fig=TRUE>>=

births2 = births
births2$lowbirthweight<-NULL
births2$premie<-NULL
Selection<-regsubsets(weight~fage+mage+weeks+gender+habit+whitemom, data=births2,nbest=4) 
@

\subsubsection*{Residuals and Leverage of NC Births Data}

Model Diagnostics. After fitting regession models we need to determine whether our model assumptions can be used before actually making an inference. We should look for violations and look for the consequential inferential procedures that would be void for these incorrect conclusions.


Model Diagnostics combines both graphical and statistical methods. 

Using our formal model:
<<echo=FALSE, message=FALSE>>=
results<-(lm(weight ~ weeks+ + marital + gained + gender + habit + whitemom,births2))
results.table<-xtable(results)
@

\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
\hline
& Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\
\hline
(Intercept) & -6.2423 & 0.4581 & -13.63 & 0.0000 \\
weeks & 0.3290 & 0.0120 & 27.51 & 0.0000 \\
maritalnot married & 0.2651 & 0.0757 & 3.50 & 0.0005 \\
gained & 0.0093 & 0.0024 & 3.81 & 0.0001 \\
gendermale & 0.3784 & 0.0690 & 5.49 & 0.0000 \\
habitsmoker & -0.3888 & 0.1048 & -3.71 & 0.0002 \\
whitemomwhite & 0.2121 & 0.0813 & 2.61 & 0.0092 \\
\hline
\end{tabular}
\end{table}
Leverage = ability to move a regression model by itself by moving in the y direction.  Shifted in the y direction. Leverage is always between one and zero. Zero implies that there is no effect on the model whereas one means the lines follow the point perfectly.

<<echo=FALSE, message=FALSE,fig.height=3.5,fig.width=6>>=
lev<-hat(model.matrix(results))
plot(lev,col="blue",main="leverage")
births2[lev>0.04,]
@
After reviewing the leverage plot I wanted to check for outliers that maybe of interest. Observations 18, 287 and 969 seemed to be the most important for leverage.





<<echo=FALSE, message=FALSE,fig.height=3.5,fig.width=6>>=
#results.residuals<-resid(results)
#plot(results.residuals)

#r<-rstudent(results)
#plot(r)

cook<-cooks.distance(results)
plot(cook,ylab="Cook's Distances")
births2[cook>0.02,]

@



\subsection{Methods}
"Lowbirthweight" and the "premie" were not included in the model, because they are variables predicated on weeks and weight in categorical form. 
\subsection{Discussion}
\subsection{Conclusion}
\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%% Maritza's Analysis %%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Classification and Regression Trees (CART): Maritza Mallek}
\subsection{Introduction} Classification and Regression Trees (CARTs) are a nonparametric approach to regression. CARTs are generated through binary recursive partitioning, in which each potential independent variable used to build the model is tested to obtain the value at which the most meaningful split between two branches can be created. The rules can vary within and among R packages, but the goal is usually to minimize a value such as the sum of squared residuals, Gini index, or misclassification rate. The recursive aspect occurs as this process is repeated at each node of the tree, creating two new branches off each node until some predefined set of constraints are met, which stops the model. These constraints may include the number of observations in a node or marginal improvement in the value to be minimized.

Trees are popular because they are fairly intuitive to interpret, especially for non-statisticians, including in public health settings. At each node an equality is shown; for a given observation, if the inequality resolves as \textsc{true}, the reader follows the left branch. The alternative to CARTs is typically some form of parametric regression, such as GLM. For a doctor in a hospital, consulting a regression tree is much simpler than generating and interpreting a regression model. Because CARTs are nonparametric, the results do not explain why certain variable values result in the observed response, but in situations where researchers are interested in the likelihood and not necessarily interested in how to change an outcome, CARTs are a reasonable tool. They may be used for either exploratory or predictive data analysis.

\subsection{Methods: CART using R} Analysts running CART analysis in R typically use either the \verb|tree| or the \verb|rpart| package. The \verb|tree| package uses residuals, similarly to GLMs, while \verb|rpart| grows the tree using the Gini index of the data. In this analysis, the tree package was the primary tool. Also included are results using \verb|rpart| because better data visualization tools are available for this package, even if it is not as directly interpretable as the output from \verb|tree|.

The response variable selected for analysis by the group was \verb|weight|, also present in the dataset as the factored variable \verb|lowbirthweight|. The former is appropriate for regression tree analysis, while the latter is appropriate for classification trees. In this paper the biological significance of a 5.5 lb cutoff for low birth rate is accepted, and therefore \verb|lowbirthweight| is used. By default, observations with missing values are not used to build the tree. Consequently, only 800 observations are used to develop the tree. Standard practice in CART analysis is to first grow a tree, then ``prune" it by removing lower branches to avoid overfitting the data. Cross-validation is used to determine how much to prune a tree. The standard is 10-fold, and was employed here. In the first step of this analysis, all the available variables (the full model) were used to fit the data using the \verb|tree| package. Default parameters to constrain tree growth were accepted: minimum number of observations per child node = 5, smallest node size = 10, and within-node deviance parameter for nodes to be split = 0.01.


<<fullmodel, fig.height=5, fig.width=6, echo=FALSE, eval=FALSE>>=
form1 = lowbirthweight ~ fage + mage + mature + weeks + visits + marital + gained + gender + habit + whitemom
bt1 = tree(form1, data = births)
summary(bt1)
plot(bt1)
text(bt1, cex=0.7)
# Residual mean deviance:  0.3 = 237 / 790
bt1.cv = cv.tree(bt1)
bt1.p = prune.tree(bt1, best=3)
summary(bt1.p)
plot(bt1.p)
text(bt1.p, cex=1)
@

\subsection{Results}
\subsubsection{Classification tree analysis using the tree package} 
\paragraph{Investigation of the full model} Results from the initial analysis showed that \verb|weeks| is by far the most important predictor variable available. \verb|Gained|, \verb|marital|, and \verb|visits| were also used to construct the tree, which had 10 nodes, a residual mean deviance of 0.3, and a misclassification error rate of 0.0475. Cross-validation showed the best tree had just 2-3 nodes. Pruning based on this finding (refitting and constraining tree growth) at 3 nodes resulted in a tree in which \verb|weeks| was the only relevant predictor variable. The residual mean deviance and misclassification error rate increased slightly, to 0.363 and 0.0538, respectively.


<<prunedtree1, fig.height=3.1, fig.width=6, echo=FALSE, message=FALSE, fig.cap="Classification trees generated with the full model (left) and the alternative model (right). For the full model, 10-fold cross-validation was used to prune the tree, and the final result is pictured here. For the alternative model, pruning techniques reduced the model to 1 node (no tree) and so are not shown.">>=
form1 = lowbirthweight ~ fage + mage + mature + weeks + visits + marital + gained + gender + habit + whitemom
bt1 = tree(form1, data = births)
bt1.cv = cv.tree(bt1)
bt1.p = prune.tree(bt1, best=3)
par(mfrow = c(1, 2), mar=c(2,2,2,2))
plot(bt1.p)
text(bt1.p, cex=0.8, all=TRUE)
################
form2 = lowbirthweight ~ fage + mage  + marital + gender + habit + whitemom
bt2 = tree(form2, data=births)
plot(bt2)
text(bt2, cex=1, all=TRUE, pretty=8)
#bt3 = rpart(form2, data=births, method="class", control=rpart.control(minbucket=5, cp=0.001, maxcompete=7))
#fancyRpartPlot(bt3)

@

\paragraph{Investigation of the alternative model} While the finding of \verb|weeks| as the key predictor of low birth weight is reasonable, both logically and by an examination of associated metrics, it is not particularly interesting. A review of the variables used in the model shows that \verb|visits| and \verb|gained|, as well as \verb|weeks|, represent data recorded at the same time as \verb|weight|. Lacking information linked to gestational ages before birth, it may be disingenous to use these in a predictive framework. Given this reasoning, a new model was specified that omitted those variables, specified as:
\begin{verbatim}
lowbirthweight ~ fage + mage + marital + gender + habit + whitemom
\end{verbatim}

<<echo=FALSE, include=FALSE>>=
form2 = lowbirthweight ~ fage + mage  + marital + gender + habit + whitemom
bt2 = tree(form2, data=births)
@

<<echo=FALSE, include=FALSE>>=
bt2
summary(bt2)
plot(bt2)
text(bt2, cex=1, all=TRUE, pretty=8)
#plot(cv.tree(bt2))
@

<<echo=FALSE, include=FALSE, fig.height=4>>=
bt2.adj = tree(form2, data=births, control=tree.control(1000, mincut=5, minsize=10, mindev=0.005))
summary(bt2.adj)
plot(bt2.adj)
text(bt2.adj, cex=.6, pretty=10)

bt2.adj.cv = cv.tree(bt2.adj)
bt2.adj.p = prune.tree(bt2.adj, best=which.min(bt2.adj.cv$dev))
plot(bt2.adj.p)
text(bt2.adj.p, cex=1, all=TRUE, pretty=10)
@

Running the classification tree function using the new model produced a tree with just three nodes using the variable \verb|marital|. However, none of the terminal branches included a set of observations that are more than 50\% low birth weight. Thus this model always predicts ``not low'' birth weight. Reducing the stopping criteria allows the tree to grow more branches, and is one way to force a tree to better fit a dataset. In this analysis, the within-node deviance (\verb|mindev|) was halved. As a result, all variables but \verb|gender| were used to produce the tree, which had 18 terminal nodes, a residual mean deviance of 0.5643, and a misclassification error rate of 0.09674. One of the terminal nodes predicted low birth weight for the observations at that node.

\subsubsection{Classification tree analysis using the rpart package} The \verb|rpart| package was briefly explored to further examine the data. The reduced model was used and the default settings regulating tree growth were again adjusted simply to obtain a tree with any branches at all. The minimum number of observations in a terminal node was reduced to 5 and the complexity parameter was reduced to 0.001 (an order of magnitude less than the default). Results differed from those associated with the \verb|tree| package since splits were based on the Gini index. All predictor variables had some importance, although \verb|mage| and \verb|marital| were the most influential. Again, the difficulty of producing trees that isolated low birth weight suggests that the predictor variables used are not necessarily significant, especially for prediction.


<<echo=FALSE, include=FALSE, results='hide'>>=
bt3 = rpart(form2, data=births, method="class", control=rpart.control(minbucket=5, cp=0.001, maxcompete=7))
printcp(bt3)
plotcp(bt3)
print(bt3)
summary(bt3)
plot(bt3, uniform=F, main="Classification Tree for Low Birth Weight")
text(bt3, use.n=TRUE, all=TRUE, pretty=10, cex=0.6)
fancyRpartPlot(bt3)

cparam = bt3$cptable[which.min(bt3$cptable[,"xerror"]),"CP"]

@

\subsection{Discussion and Conclusions}
\subsubsection{Classification Trees vs. GLM}
<<echo=FALSE, include=FALSE, results='hide'>>=
# compare tree to second-order GLM
glm1 = glm(form2, data=births, family=binomial)
summary(glm1)
# Residual deviance: 457.24  on 791  degrees of freedom
457.24/791
@
The full model was analyzed in R as a generalized linear model (GLM) and logistic regression. Predictor variables hospital \verb|visits| and weight \verb|gained| were significant at the 0.01 level, while smoking and white mom were significant at the 0.1 level. All other variables did not show significance at the 0.1 or smaller level. The classification tree had slightly lower residual deviance than the GLM (0.5014 and 0.5781, respectively). Statistically, the difference between them falls into a subjective zone. While trees are theoretically easy to use, in the case of the selected dataset and response variable, using a tree may generate confusion since it did not make a strong prediction for low birth weight.

Classification trees were of mixed use in exploring this dataset. Four of the predictor variables in the initial model were needed to segment the data. Results showed that none of the recorded variables were particularly well-suited for predicting low birth weight, but any explanations are simple speculation. The pruned, cross-validated tree composed using the full model had only 3 nodes and only one variable was used to create the tree. The trees make clear that \verb|weeks| is a key variable, this seems an obvious result. The second model suggests that further exploration of the associated implications of mother's marital status may lead to variables with some predictive power, which the dataset currently lacks as far as can be detected within the classification tree framework.

\subsubsection{An Interesting Negative Result} This analysis produced an interesting negative result: none of the provided variables are highly significant predictors of low birth weight, especially when discounting variables measured at the same time as birth weight, as in the alternative model. No obvious interactions between variables were revealed through the analysis. To some extent, this is a disappointing outcome because a set of key predictor variables for this attribute was not found. However, the results may be useful because they suggest that additional variables or additional data points over time are needed to understand the relationship between the habits and practices of mothers and health outcomes like low birth weight. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%% Steele's Analysis %%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%% 1 Page Discussion/Conclusions %%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Group Discussion and Conclusions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Summary stats needed for table of variables %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Use for number of missing values in each distribution
<<echo=FALSE,eval=FALSE>>=
summary(births)
@

% FATHERS AGE CONFIDENCE INTERVALS:
<<echo=FALSE,eval=FALSE>>=

# Mean and variance
mean(fage,na.rm=TRUE)
var(fage,na.rm=TRUE)

# calculation of n = (number of values in fage) - (number NAs)
1000-171


# 95 percent CI for mean
# lower bound, upper bound
mean(fage,na.rm=TRUE) - qnorm(.975)*(sd(fage,na.rm=TRUE)/sqrt(829))
mean(fage,na.rm=TRUE) + qnorm(.975)*(sd(fage,na.rm=TRUE)/sqrt(829))

# 95 percent CI for variance
# lower bound, upper bound
((829-1)*var(fage,na.rm=TRUE))/qchisq(0.975,df=(829-1))
((829-1)*var(fage,na.rm=TRUE))/qchisq(0.025,df=(829-1))

@


% MOTHERS AGE CONFIDENCE INTERVALS:
<<echo=FALSE,eval=FALSE>>=

# Mean and variance
mean(mage,na.rm=TRUE)
var(mage,na.rm=TRUE)

# No missing values in mage -> n=1000

# 95 percent CI for mean
# lower bound, upper bound
mean(mage,na.rm=TRUE) - qnorm(.975)*(sd(mage,na.rm=TRUE)/sqrt(1000))
mean(mage,na.rm=TRUE) + qnorm(.975)*(sd(mage,na.rm=TRUE)/sqrt(1000))

# 95 percent CI for variance
# lower bound, upper bound
((1000-1)*var(mage,na.rm=TRUE))/qchisq(0.975,df=(1000-1))
((1000-1)*var(mage,na.rm=TRUE))/qchisq(0.025,df=(1000-1))

@


% WEEKS CONFIDENCE INTERVALS:
<<echo=FALSE,eval=FALSE>>=

# Mean and variance
mean(weeks,na.rm=TRUE)
var(weeks,na.rm=TRUE)

# calculation of n = (number of values in fage) - (number NAs)
1000-2


# 95 percent CI for mean
# lower bound, upper bound
mean(weeks,na.rm=TRUE) - qnorm(.975)*(sd(weeks,na.rm=TRUE)/sqrt(998))
mean(weeks,na.rm=TRUE) + qnorm(.975)*(sd(weeks,na.rm=TRUE)/sqrt(998))

# 95 percent CI for variance
# lower bound, upper bound
((998-1)*var(weeks,na.rm=TRUE))/qchisq(0.975,df=(998-1))
((998-1)*var(weeks,na.rm=TRUE))/qchisq(0.025,df=(998-1))

@

% VISITS CONFIDENCE INTERVALS:
<<echo=FALSE,eval=FALSE>>=

# Mean and variance
mean(visits,na.rm=TRUE)
var(visits,na.rm=TRUE)

# calculation of n = (number of values in fage) - (number NAs)
1000-9


# 95 percent CI for mean
# lower bound, upper bound
mean(visits,na.rm=TRUE) - qnorm(.975)*(sd(visits,na.rm=TRUE)/sqrt(991))
mean(visits,na.rm=TRUE) + qnorm(.975)*(sd(visits,na.rm=TRUE)/sqrt(991))

# 95 percent CI for variance
# lower bound, upper bound
((991-1)*var(visits,na.rm=TRUE))/qchisq(0.975,df=(991-1))
((991-1)*var(visits,na.rm=TRUE))/qchisq(0.025,df=(991-1))

@

% GAINED CONFIDENCE INTERVALS:
<<echo=FALSE,eval=FALSE>>=

# Mean and variance
mean(gained,na.rm=TRUE)
var(gained,na.rm=TRUE)

# calculation of n = (number of values in fage) - (number NAs)
1000-27


# 95 percent CI for mean
# lower bound, upper bound
mean(gained,na.rm=TRUE) - qnorm(.975)*(sd(gained,na.rm=TRUE)/sqrt(973))
mean(gained,na.rm=TRUE) + qnorm(.975)*(sd(gained,na.rm=TRUE)/sqrt(973))

# 95 percent CI for variance
# lower bound, upper bound
((973-1)*var(gained,na.rm=TRUE))/qchisq(0.975,df=(973-1))
((973-1)*var(gained,na.rm=TRUE))/qchisq(0.025,df=(973-1))

@

% WEIGHT CONFIDENCE INTERVALS:
<<echo=FALSE,eval=FALSE>>=

# Mean and variance
mean(weight,na.rm=TRUE)
var(weight,na.rm=TRUE)

# calculation of n = (number of values in fage) - (number NAs)
1000-0


# 95 percent CI for mean
# lower bound, upper bound
mean(weight,na.rm=TRUE) - qnorm(.975)*(sd(weight,na.rm=TRUE)/sqrt(1000))
mean(weight,na.rm=TRUE) + qnorm(.975)*(sd(weight,na.rm=TRUE)/sqrt(1000))

# 95 percent CI for variance
# lower bound, upper bound
((1000-1)*var(weight,na.rm=TRUE))/qchisq(0.975,df=(1000-1))
((1000-1)*var(weight,na.rm=TRUE))/qchisq(0.025,df=(1000-1))

@


\end{document}
